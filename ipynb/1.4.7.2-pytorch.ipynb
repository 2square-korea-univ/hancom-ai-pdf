{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd079e3",
   "metadata": {},
   "source": [
    "# MNIST 다중 클래스 분류 (PyTorch 활용)\n",
    "\n",
    "## 1. 들어가며\n",
    "\n",
    "NumPy로 신경망의 기본 원리를 깊이 이해했고, Keras를 사용하여 프레임워크의 편리함을 경험했습니다. 이제 PyTorch를 사용하여 MNIST 손글씨 숫자 데이터를 분류하는 다중 클래스 분류 문제를 해결해 보겠습니다.\n",
    "\n",
    "PyTorch는 유연성이 뛰어나 연구 개발에 많이 사용되며, \"Pythonic\"한 코딩 스타일을 선호하는 분들에게 인기가 많습니다. Keras와는 달리 학습 루프를 직접 작성해야 하므로, 신경망 내부 동작 과정을 더 명확하게 이해하는 데 도움이 될 수 있습니다.\n",
    "\n",
    "이번 노트북에서는 PyTorch를 사용하여 다음 내용들을 학습합니다.\n",
    "\n",
    "1.  **PyTorch를 이용한 MNIST 데이터셋 로딩 및 전처리**\n",
    "2.  **데이터 로더(DataLoader)를 사용한 미니 배치 처리**\n",
    "3.  **다중 클래스 분류를 위한 신경망 모델 정의 (`torch.nn.Module`)**\n",
    "4.  **다중 클래스 분류를 위한 손실 함수 (`nn.CrossEntropyLoss`)**\n",
    "5.  **옵티마이저 (`torch.optim.Adam`) 사용**\n",
    "6.  **PyTorch에서의 학습 루프 (순전파, 손실 계산, 역전파, 옵티마이저 스텝)**\n",
    "7.  **모델 평가 및 예측 (`model.eval()`, `torch.no_grad()`)**\n",
    "8.  **과적합 방지를 위한 Dropout 적용**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c5640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 임포트합니다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader # 데이터셋 및 로더를 위해 필요\n",
    "import torchvision # 이미지 관련 데이터셋 및 변환을 위해 필요\n",
    "import torchvision.transforms as transforms # 이미지 변환을 위해 필요\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # 학습 과정 시각화를 위해 필요\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c38b4",
   "metadata": {},
   "source": [
    "\n",
    "*   `torchvision`: PyTorch에서 이미지 데이터셋 (MNIST, CIFAR10 등)과 이미지 변환(Transform)을 편리하게 사용할 수 있도록 제공하는 라이브러리입니다.\n",
    "*   `torch.utils.data.Dataset`, `DataLoader`: PyTorch에서 데이터를 효율적으로 불러오고 미니 배치 단위로 제공하는 핵심 클래스입니다.\n",
    "*   `device`: 모델과 데이터를 CPU 또는 GPU로 이동시키기 위해 설정합니다. GPU가 있다면 학습 속도를 크게 높일 수 있습니다.\n",
    "\n",
    "## 2. MNIST 데이터셋 로딩 및 준비 (PyTorch 스타일)\n",
    "\n",
    "PyTorch에서는 `torchvision.datasets`를 사용하여 MNIST 데이터를 쉽게 로드하고, `torchvision.transforms`를 사용하여 필요한 전처리를 적용합니다. `DataLoader`는 이 데이터셋을 기반으로 미니 배치 단위의 데이터를 제공합니다.\n",
    "\n",
    "### 2.1 데이터 로딩 및 변환 (Transform)\n",
    "\n",
    "`transforms.ToTensor()`는 PIL Image나 NumPy 배열 데이터를 PyTorch Tensor로 변환하고, 픽셀 값을 자동으로 [0, 1] 범위로 스케일링(정규화) 해줍니다. 이는 Keras에서 `astype('float32') / 255.0` 했던 것과 동일한 효과입니다.\n",
    "\n",
    "`transforms.Normalize()`는 픽셀 값을 평균 0, 표준 편차 1을 갖도록 추가적인 정규화를 수행합니다. 이는 모델 학습 안정성에 도움이 됩니다. MNIST 데이터셋의 평균과 표준 편차는 알려져 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에 적용할 변환 정의\n",
    "# ToTensor(): 이미지를 Tensor로 변환하고 [0, 1]로 정규화\n",
    "# Normalize(): 평균 0.1307, 표준 편차 0.3081로 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # MNIST 데이터셋의 평균과 표준편차\n",
    "])\n",
    "\n",
    "# MNIST 학습 및 테스트 데이터셋 로딩\n",
    "# root: 데이터셋을 저장할 경로\n",
    "# train=True: 학습 데이터셋, train=False: 테스트 데이터셋\n",
    "# download=True: 데이터셋이 없으면 다운로드\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(f\"학습 데이터셋 크기: {len(train_dataset)}\")\n",
    "print(f\"테스트 데이터셋 크기: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3530303",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 데이터 로더 (DataLoader) 설정 (미니 배치)\n",
    "\n",
    "`DataLoader`는 데이터셋에서 미니 배치 크기만큼 데이터를 자동으로 가져와서 Tensor 형태로 제공합니다. 학습 시에는 `shuffle=True`로 설정하여 데이터를 무작위로 섞어 모델이 데이터 순서에 의존하지 않도록 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정\n",
    "batch_size = 64 # 한 번에 처리할 미니 배치 크기\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) # 테스트 시에는 섞을 필요 없음\n",
    "\n",
    "# 데이터 로더에서 첫 번째 배치 데이터 형태 확인\n",
    "# iter(train_loader).next() 대신 next(iter(train_loader)) 사용 (Python 3.6 이상 권장)\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"첫 번째 배치 이미지 형태: {images.shape}\") # (batch_size, 채널, 높이, 너비) -> (64, 1, 28, 28)\n",
    "print(f\"첫 번째 배치 레이블 형태: {labels.shape}\") # (batch_size) -> (64)\n",
    "print(f\"첫 번째 배치 레이블 (처음 5개): {labels[:5]}\") # 레이블은 원본 정수 형태입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ae3ea",
   "metadata": {},
   "source": [
    "\n",
    "*   PyTorch의 이미지 Tensor는 `(Batch Size, Channels, Height, Width)` 순서입니다. MNIST는 흑백 이미지이므로 채널이 1입니다.\n",
    "*   레이블은 다중 클래스 분류를 위해 정수 형태(0~9) 그대로 사용합니다. 이는 Keras의 `categorical_crossentropy`와 달리 PyTorch의 `nn.CrossEntropyLoss`는 원본 정수 레이블을 입력받기 때문입니다.\n",
    "\n",
    "### 2.3 데이터 시각화 (DataLoader에서 가져온 샘플 확인)\n",
    "\n",
    "`DataLoader`에서 가져온 배치의 첫 번째 이미지를 시각화해 봅시다. `Normalize`를 적용했기 때문에 픽셀 값이 음수가 될 수도 있지만, 시각화 라이브러리는 자동으로 스케일링하여 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 배치에서 이미지 하나를 시각화 (정규화된 값일 수 있습니다)\n",
    "# Tensor를 NumPy 배열로 변환하고 채널 차원 제거 (1, 28, 28) -> (28, 28)\n",
    "img_tensor = images[0].squeeze() # 채널 차원이 1이면 제거\n",
    "img_numpy = img_tensor.numpy()\n",
    "\n",
    "plt.imshow(img_numpy, cmap='gray')\n",
    "plt.title(f\"Label: {labels[0].item()}\") # Tensor의 값을 Python 숫자로 가져옴\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc87653",
   "metadata": {},
   "source": [
    "\n",
    "## 3. 신경망 모델 정의 (PyTorch `nn.Module`)\n",
    "\n",
    "PyTorch에서 신경망 모델은 `torch.nn.Module` 클래스를 상속받아 정의합니다.\n",
    "\n",
    "*   `__init__` 메서드에서는 모델의 구성 요소(레이어 등)를 정의합니다.\n",
    "*   `forward` 메서드에서는 입력 데이터가 모델을 통과하는 순서를 정의합니다. Keras Sequential API의 레이어 순서와 같습니다.\n",
    "\n",
    "여기서도 Keras 예제와 유사하게 입력층(이미지 플래트닝), 은닉층(ReLU), 출력층(Softmax는 손실 함수 내장)으로 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe18cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파라미터 설정\n",
    "input_size = 28 * 28 # 784\n",
    "hidden_size = 128    # 은닉층 뉴런 수 (변경 가능)\n",
    "num_classes = 10     # 출력층 뉴런 수 (0~9 클래스)\n",
    "learning_rate = 0.001 # 학습률 (Adam 사용 시 이 값부터 시작해 보는 경우가 많습니다)\n",
    "epochs = 10          # 전체 데이터셋 반복 횟수\n",
    "\n",
    "# 신경망 모델 클래스 정의\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) # 첫 번째 선형 레이어 (입력 -> 은닉)\n",
    "        self.relu = nn.ReLU()                       # ReLU 활성화 함수\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 두 번째 선형 레이어 (은닉 -> 출력)\n",
    "        # Softmax는 CrossEntropyLoss 안에 포함되어 있으므로 마지막에 따로 적용하지 않습니다.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이미지를 (batch_size, 1, 28, 28)에서 (batch_size, 784)로 펼침\n",
    "        x = x.reshape(-1, input_size) # -1은 batch_size에 맞춰 자동으로 계산\n",
    "\n",
    "        out = self.fc1(x)     # 첫 번째 선형 변환\n",
    "        out = self.relu(out)  # ReLU 활성화\n",
    "        out = self.fc2(out)     # 두 번째 선형 변환 (출력층)\n",
    "        # 마지막 출력은 클래스별 점수 (logits) 입니다.\n",
    "        return out\n",
    "\n",
    "# 모델 인스턴스 생성 및 디바이스(CPU/GPU)로 이동\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "print(\"모델 구조:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307782c",
   "metadata": {},
   "source": [
    "\n",
    "*   `nn.Linear(in_features, out_features)`: 완전 연결(Fully Connected) 레이어입니다. `in_features`는 입력 뉴런 수, `out_features`는 출력 뉴런 수입니다. 가중치(W)와 편향(b)을 포함합니다.\n",
    "*   `nn.ReLU()`: ReLU 활성화 함수입니다.\n",
    "*   `reshape(-1, input_size)`: `forward` 메서드에서 이미지 Tensor의 형태를 학습에 사용할 수 있도록 펼쳐주는 부분입니다. `-1`은 배치 크기를 의미하며, PyTorch가 자동으로 계산합니다.\n",
    "\n",
    "## 4. 손실 함수 및 옵티마이저 정의\n",
    "\n",
    "PyTorch에서 손실 함수는 `torch.nn` 모듈에, 옵티마이저는 `torch.optim` 모듈에 있습니다.\n",
    "\n",
    "*   **손실 함수:** 다중 클래스 분류에는 `nn.CrossEntropyLoss`를 사용합니다. 이 함수는 모델의 출력(Logits, 즉 Softmax 적용 전의 원시 점수)과 원본 정수 레이블을 입력받아 손실을 계산합니다. 내부적으로 Softmax와 Negative Log Likelihood Loss를 결합한 형태입니다.\n",
    "*   **옵티마이저:** Adam 옵티마이저를 사용합니다. `optim.Adam(model.parameters(), lr=learning_rate)` 형태로 모델의 모든 학습 가능한 파라미터와 학습률을 전달하여 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba959c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의: Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의: Adam 옵티마이저\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"손실 함수 및 옵티마이저 정의 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d5bc4",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 모델 학습 (PyTorch 학습 루프)\n",
    "\n",
    "PyTorch에서는 학습 루프를 직접 작성해야 합니다. 기본적인 학습 루프는 다음과 같습니다.\n",
    "\n",
    "1.  **Epoch 반복:** 전체 데이터셋을 몇 번 학습할지 결정합니다.\n",
    "2.  **Batch 반복:** 각 Epoch 내에서 `DataLoader`를 통해 미니 배치 단위로 데이터를 가져옵니다.\n",
    "3.  **데이터 디바이스 이동:** 배치 데이터를 CPU 또는 GPU(`device` 변수)로 이동시킵니다.\n",
    "4.  **기울기 초기화:** 이전 배치에서 계산된 기울기를 0으로 초기화합니다 (`optimizer.zero_grad()`).\n",
    "5.  **순전파:** 모델에 입력 데이터를 넣어 예측 값을 계산합니다 (`outputs = model(inputs)`).\n",
    "6.  **손실 계산:** 예측 값과 실제 레이블을 사용하여 손실 함수 값을 계산합니다 (`loss = criterion(outputs, labels)`).\n",
    "7.  **역전파:** 손실 함수 값을 바탕으로 모델의 모든 학습 가능한 파라미터에 대한 기울기를 계산합니다 (`loss.backward()`).\n",
    "8.  **가중치 업데이트:** 계산된 기울기를 사용하여 옵티마이저가 모델의 가중치를 업데이트합니다 (`optimizer.step()`).\n",
    "9.  **손실 및 정확도 기록:** 학습 과정을 모니터링하기 위해 배치별 손실과 정확도를 기록합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2527d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 기록을 위한 리스트\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(f\"모델 학습 시작 (Epochs: {epochs}, Batch Size: {batch_size})...\")\n",
    "\n",
    "# 모델을 학습 모드로 설정 (Dropout 등이 활성화됨)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # 데이터 로더를 통해 미니 배치 데이터 가져오기\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 데이터를 지정된 디바이스로 이동 (CPU 또는 GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # ----------- 핵심 학습 단계 -----------\n",
    "        # 1. 이전 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. 순전파: 입력 데이터를 모델에 통과시켜 출력(예측 값) 계산\n",
    "        outputs = model(images) # 출력은 클래스별 점수(logits)\n",
    "\n",
    "        # 3. 손실 계산: 예측 값(outputs)과 실제 레이블(labels) 비교\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 4. 역전파: 손실을 바탕으로 기울기 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. 가중치 업데이트: 계산된 기울기를 사용하여 모델 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # -------------------------------------\n",
    "\n",
    "        running_loss += loss.item() # 배치별 손실 누적 (.item()으로 Tensor 값을 Python 숫자로 변환)\n",
    "\n",
    "        # 정확도 계산 (학습 과정 모니터링용)\n",
    "        # outputs에서 가장 높은 점수를 갖는 클래스 인덱스 찾기\n",
    "        # dim=1은 두 번째 차원 (클래스 차원)을 기준으로 argmax 계산\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0) # 현재 배치의 샘플 수 누적\n",
    "        correct_predictions += (predicted == labels).sum().item() # 예측과 실제가 일치하는 경우 누적\n",
    "\n",
    "        # (선택 사항) 배치별 진행 상황 출력\n",
    "        # if (i + 1) % 100 == 0: # 100 배치마다 출력\n",
    "        #     print(f'  Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "        #           f'Loss: {loss.item():.4f}, Acc: {(correct_predictions/total_samples):.4f}')\n",
    "\n",
    "\n",
    "    # 에포크 종료 후 평균 손실 및 정확도 계산 및 기록\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {epoch_loss:.4f}, Average Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3babdfb",
   "metadata": {},
   "source": [
    "\n",
    "이 학습 루프는 PyTorch를 사용할 때 가장 기본이 되는 형태입니다. 각 줄의 의미와 순서를 잘 이해하는 것이 중요합니다.\n",
    "\n",
    "### 학습 과정 시각화\n",
    "\n",
    "기록해 둔 에포크별 손실과 정확도를 그래프로 그려봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 손실(Loss) 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), train_losses)\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "\n",
    "# 정확도(Accuracy) 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), train_accuracies)\n",
    "plt.title('Training Accuracy per Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183434f",
   "metadata": {},
   "source": [
    "\n",
    "## 6. 모델 평가\n",
    "\n",
    "학습이 완료된 모델의 성능을 테스트 데이터셋으로 평가합니다. 평가 시에는 기울기 계산이 필요 없으므로 `torch.no_grad()` 컨텍스트 매니저를 사용하고, 모델을 평가 모드(`model.eval()`)로 설정합니다. 평가 모드는 Dropout과 같은 특정 레이어의 작동 방식을 변경합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"모델 평가 시작...\")\n",
    "# 모델을 평가 모드로 설정 (Dropout 등이 비활성화됨)\n",
    "model.eval()\n",
    "\n",
    "# 기울기 계산을 비활성화 (메모리 사용량 감소, 연산 속도 향상)\n",
    "with torch.no_grad():\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    running_test_loss = 0.0\n",
    "\n",
    "    # 테스트 데이터 로더를 통해 배치 데이터 가져오기\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 순전파 (예측)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_test_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        _, predicted = torch.max(outputs.data, 1) # 가장 높은 점수를 갖는 클래스 인덱스\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item() # 예측과 실제가 일치하는 경우\n",
    "\n",
    "    # 테스트 데이터셋 전체에 대한 평균 손실 및 정확도 계산\n",
    "    test_loss = running_test_loss / len(test_loader)\n",
    "    test_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"테스트 손실(Loss): {test_loss:.4f}\")\n",
    "    print(f\"테스트 정확도(Accuracy): {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"모델 평가 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b149fc",
   "metadata": {},
   "source": [
    "\n",
    "테스트 정확도는 모델이 학습되지 않은 새로운 데이터에 대해 얼마나 잘 작동하는지 보여줍니다.\n",
    "\n",
    "## 7. 모델 예측\n",
    "\n",
    "학습된 모델로 개별 샘플에 대한 예측을 수행해 봅시다. 예측 시에도 `model.eval()`과 `torch.no_grad()`를 사용합니다. 모델 출력은 Logits(점수)이므로, 이를 확률로 변환하기 위해 Softmax를 적용한 후, 가장 높은 확률을 갖는 클래스를 선택합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋에서 이미지 샘플 하나 가져오기\n",
    "# batch_size가 1인 새로운 DataLoader를 사용하거나, 기존 DataLoader에서 하나씩 가져옵니다.\n",
    "# 여기서는 test_dataset에서 직접 샘플을 가져와서 배치 형태로 만듭니다.\n",
    "sample_index = 15 # 예측해 볼 샘플 인덱스 (예: 15번째 이미지)\n",
    "sample_image, sample_label = test_dataset[sample_index]\n",
    "\n",
    "# 모델에 입력하기 위해 (채널, 높이, 너비) -> (배치, 채널, 높이, 너비) 형태로 변환\n",
    "# unsqueeze(0)은 맨 앞에 차원을 하나 추가하여 배치 차원을 만듭니다.\n",
    "sample_image_input = sample_image.unsqueeze(0).to(device)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# 기울기 계산 비활성화\n",
    "with torch.no_grad():\n",
    "    # 예측 수행\n",
    "    output = model(sample_image_input) # 출력은 (1, 10) 형태의 logits\n",
    "\n",
    "    # 예측 결과(logits)를 확률로 변환 (Softmax 적용)\n",
    "    probabilities = torch.softmax(output, dim=1) # dim=1은 클래스 차원\n",
    "\n",
    "    # 가장 높은 확률을 갖는 클래스 인덱스 찾기\n",
    "    _, predicted_class = torch.max(probabilities, 1)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"모델 예측 결과 (Logits): {output}\")\n",
    "print(f\"모델 예측 결과 (Probabilities): {probabilities}\")\n",
    "print(f\"예측된 클래스: {predicted_class.item()}\") # Tensor 값을 Python 숫자로\n",
    "print(f\"실제 레이블: {sample_label}\")\n",
    "\n",
    "# 이미지 시각화\n",
    "# Tensor를 NumPy 배열로 변환하고 채널 차원 제거\n",
    "img_tensor = sample_image.squeeze()\n",
    "img_numpy = img_tensor.numpy()\n",
    "\n",
    "plt.imshow(img_numpy, cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_class.item()}, Actual: {sample_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6c77c",
   "metadata": {},
   "source": [
    "\n",
    "## 8. 과적합 방지를 위한 Dropout 적용 (PyTorch)\n",
    "\n",
    "Keras와 마찬가지로 PyTorch에서도 `nn.Dropout` 레이어를 사용하여 Dropout을 적용할 수 있습니다. `nn.Dropout(p=rate)` 형태로 사용하며, `p`는 드롭아웃 비율(0~1)입니다.\n",
    "\n",
    "Dropout 레이어는 `__init__` 메서드에서 정의하고, `forward` 메서드에서 활성화 함수 뒤에 적용하는 것이 일반적입니다. PyTorch의 `nn.Dropout`은 `model.train()`일 때만 작동하고 `model.eval()`일 때는 자동으로 비활성화됩니다.\n",
    "\n",
    "Dropout을 추가한 새로운 모델을 정의하고 학습시켜 봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Dropout을 추가한 PyTorch 모델 구성 ---\")\n",
    "\n",
    "dropout_rate = 0.2 # 20%의 뉴런을 비활성화\n",
    "\n",
    "# 신경망 모델 클래스 정의 (Dropout 추가)\n",
    "class NeuralNetWithDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout_rate=0.5):\n",
    "        super(NeuralNetWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate) # Dropout 레이어 추가\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이미지를 펼침\n",
    "        x = x.reshape(-1, input_size)\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out) # ReLU 활성화 후 Dropout 적용\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Dropout 포함 모델 인스턴스 생성 및 디바이스로 이동\n",
    "model_with_dropout = NeuralNetWithDropout(input_size, hidden_size, num_classes, dropout_rate).to(device)\n",
    "\n",
    "print(\"모델 구조 (Dropout 포함):\")\n",
    "print(model_with_dropout)\n",
    "\n",
    "# Dropout 포함 모델에 대한 손실 함수 및 옵티마이저 정의\n",
    "criterion_dropout = nn.CrossEntropyLoss()\n",
    "optimizer_dropout = optim.Adam(model_with_dropout.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\nDropout 포함 모델 학습 시작...\")\n",
    "\n",
    "# 학습 과정 기록을 위한 리스트\n",
    "train_losses_dropout = []\n",
    "train_accuracies_dropout = []\n",
    "\n",
    "# 모델을 학습 모드로 설정\n",
    "model_with_dropout.train()\n",
    "\n",
    "for epoch in range(epochs): # Keras 예제와 동일하게 10 에포크\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer_dropout.zero_grad()\n",
    "        outputs = model_with_dropout(images)\n",
    "        loss = criterion_dropout(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_dropout.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    train_losses_dropout.append(epoch_loss)\n",
    "    train_accuracies_dropout.append(epoch_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {epoch_loss:.4f}, Average Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "print(\"Dropout 포함 모델 학습 완료!\")\n",
    "\n",
    "# Dropout 포함 모델 평가\n",
    "print(\"\\nDropout 포함 모델 평가 시작...\")\n",
    "model_with_dropout.eval() # 평가 모드 설정\n",
    "with torch.no_grad():\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    running_test_loss = 0.0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_with_dropout(images)\n",
    "        loss = criterion_dropout(outputs, labels)\n",
    "        running_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss_dropout = running_test_loss / len(test_loader)\n",
    "    test_accuracy_dropout = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Dropout 포함 모델 테스트 손실(Loss): {test_loss_dropout:.4f}\")\n",
    "    print(f\"Dropout 포함 모델 테스트 정확도(Accuracy): {test_accuracy_dropout:.4f}\")\n",
    "\n",
    "# 학습 과정 시각화 (Dropout 포함 모델)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 손실(Loss) 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), train_losses_dropout)\n",
    "plt.title('Training Loss per Epoch (with Dropout)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "\n",
    "# 정확도(Accuracy) 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), train_accuracies_dropout)\n",
    "plt.title('Training Accuracy per Epoch (with Dropout)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1f1a6",
   "metadata": {},
   "source": [
    "\n",
    "MNIST 데이터셋은 상대적으로 단순하기 때문에 Dropout의 효과가 드라마틱하지 않을 수 있습니다. 하지만 더 크고 복잡한 데이터셋이나 모델에서는 과적합을 방지하고 테스트 성능을 향상시키는 데 중요한 역할을 합니다.\n",
    "\n",
    "## 9. 마치며\n",
    "\n",
    "PyTorch를 사용하여 MNIST 다중 클래스 분류 모델을 성공적으로 구현하고 학습시켰습니다! Keras와는 다른 PyTorch만의 데이터 처리 (`Dataset`, `DataLoader`, `transforms`) 및 모델 정의 (`nn.Module`, `nn.Linear`, `nn.ReLU`) 방식, 그리고 학습 루프를 직접 작성하는 경험을 해보았습니다. 또한, 다중 클래스 분류를 위한 `nn.CrossEntropyLoss`와 일반적인 옵티마이저인 `optim.Adam`, 그리고 과적합 방지를 위한 `nn.Dropout` 사용법을 익혔습니다.\n",
    "\n",
    "이제 다음 단계로 나아가기 위한 탄탄한 기초를 PyTorch로도 다지게 되었습니다. 앞으로 PyTorch를 사용하여 다양한 딥러닝 모델(CNN, RNN 등)을 구현하고, 더 복잡한 데이터셋과 문제를 해결하는 도전을 이어갈 수 있을 것입니다.\n",
    "\n",
    "**다음 학습 추천:**\n",
    "\n",
    "*   **Convolutional Neural Network (CNN):** 이미지 처리에 특화된 강력한 네트워크입니다. PyTorch의 `nn.Conv2d`, `nn.MaxPool2d` 등을 사용하여 MNIST, CIFAR-10 등의 이미지 분류 성능을 크게 향상시킬 수 있습니다.\n",
    "*   **PyTorch Flow 깊이 이해:** `autograd` (자동 미분), `Tensor` 연산, 커스텀 `Dataset` 및 `DataLoader` 생성 등을 더 깊이 학습하여 PyTorch를 자유자재로 활용하는 능력을 키웁니다.\n",
    "*   **모델 저장 및 불러오기:** 학습된 모델을 파일로 저장하고 나중에 다시 불러와서 사용하거나 이어서 학습하는 방법을 배웁니다.\n",
    "*   **하이퍼파라미터 튜닝 도구 사용:** Optuna, Ray Tune 등 하이퍼파라미터 최적화 도구를 사용하여 자동으로 최적의 학습 파라미터를 찾는 방법을 배웁니다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler-arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

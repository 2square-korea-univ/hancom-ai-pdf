{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 23장 AI가 문맥을 파악하는 원리\n",
        "\n",
        "## <목차>\n",
        "\n",
        "- **23-1. 단어 간 유사성 측정하기**  \n",
        "- **23-2. 단어들 사이의 관계 파악하기**  \n",
        "- **23-3. 단어 사이의 관계 수정하기**  \n",
        "- **23-4. AI가 문맥을 파악하는 법**  \n",
        "- **23-5. 질문(쿼리), 단서(키), 답변(밸류)**  \n",
        "- **23-6. 트랜스포머를 위한 어텐션 만들기**  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[<img src=\"https://raw.githubusercontent.com/taehojo/taehojo.github.io/master/assets/images/linktocolab.png\" align=\"left\"/> ](https://colab.research.google.com/github/taehojo/deeplearning_4th/blob/master/colab/ch23-colab.ipynb)\n",
        "\n",
        "\n",
        "## 23-1 단어 간 유사성 측정하기\n",
        "\n",
        "### 단어 임베딩: AI가 언어를 이해하는 첫 단계\n",
        "\n",
        "단어 임베딩은 자연어처리에서 가장 기본이 되는 개념입니다. 컴퓨터는 텍스트를 직접 이해할 수 없기 때문에, 단어를 숫자로 표현해야 합니다. 즉, 텍스트 데이터를 벡터라는 수치 형태로 변환하는 과정이 필요합니다.\n",
        "\n",
        "임베딩 벡터는 단어의 의미적 관계를 수학적으로 표현합니다. 의미가 비슷한 단어들은 벡터 공간에서 서로 가까운 위치에 놓이게 됩니다. 예를 들어 '사과'와 '배'는 모두 과일이므로 벡터 공간에서 가까이 위치하게 됩니다.\n",
        "\n",
        "### 컴퓨터가 알아 들을 수 있도록 수치 형태로 변환하기\n",
        "\n",
        "아래 코드에서는 과일(귤, 딸기, 수박)과 감정 표현(미소짓다, 화내다, 웃다)을 2차원 벡터로 표현했습니다. 실제 자연어처리에서는 보통 수백 차원의 벡터를 사용하지만, 이해를 위해 2차원으로 간단히 표현했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'귤'의 임베딩 벡터: [0 6]\n",
            "'딸기'의 임베딩 벡터: [0 5]\n",
            "'수박'의 임베딩 벡터: [1 6]\n",
            "'미소짓다'의 임베딩 벡터: [6 1]\n",
            "'화내다'의 임베딩 벡터: [6 0]\n",
            "'웃다'의 임베딩 벡터: [5 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 단어와 임베딩 벡터 정의\n",
        "word_embeddings = {\n",
        "    '귤': np.array([0, 6]),\n",
        "    '딸기': np.array([0, 5]),\n",
        "    '수박': np.array([1, 6]),\n",
        "    '미소짓다': np.array([6, 1]),\n",
        "    '화내다': np.array([6, 0]),\n",
        "    '웃다': np.array([5, 0])\n",
        "}\n",
        "\n",
        "#출력해 보기\n",
        "for word, vec in word_embeddings.items():\n",
        "    print(f\"'{word}'의 임베딩 벡터: {vec}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드에서 볼 수 있듯이, 각 단어는 2차원 벡터로 표현됩니다. 첫 번째 차원은 단어가 얼마나 감정 표현에 가까운지를, 두 번째 차원은 얼마나 과일에 가까운지를 나타냅니다. 이렇게 벡터로 표현함으로써 컴퓨터는 단어 간의 관계를 수학적으로 계산할 수 있게 됩니다.\n",
        "\n",
        "### 단어를 시각화 하기\n",
        "\n",
        "단어 임베딩을 시각화하면 단어 간의 관계를 직관적으로 파악할 수 있습니다. 아래 코드는 각 단어 벡터를 2차원 평면에 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44516 (\\N{HANGUL SYLLABLE GYUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46392 (\\N{HANGUL SYLLABLE DDAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48149 (\\N{HANGUL SYLLABLE BAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48120 (\\N{HANGUL SYLLABLE MI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49548 (\\N{HANGUL SYLLABLE SO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51667 (\\N{HANGUL SYLLABLE JIS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 45236 (\\N{HANGUL SYLLABLE NAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50883 (\\N{HANGUL SYLLABLE US}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 단어와 임베딩 벡터 정의\n",
        "word_embeddings = {\n",
        "    '귤': np.array([0, 6]),\n",
        "    '딸기': np.array([0, 5]),\n",
        "    '수박': np.array([1, 6]),\n",
        "    '미소짓다': np.array([6, 1]),\n",
        "    '화내다': np.array([6, 0]),\n",
        "    '웃다': np.array([5, 0])\n",
        "}\n",
        "\n",
        "# 단어 임베딩을 시각화해 봅니다.\n",
        "plt.figure(figsize=(4, 4))\n",
        "for word, vec in word_embeddings.items():\n",
        "    plt.scatter(*vec)\n",
        "    plt.text(vec[0] + 0.1, vec[1], word)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "시각화 결과를 보면, 과일 관련 단어(귤, 딸기, 수박)는 그래프의 위쪽에 모여 있고, 감정 표현 단어(미소짓다, 화내다, 웃다)는 오른쪽에 모여 있는 것을 볼 수 있습니다. 이처럼 의미적으로 유사한 단어들은 벡터 공간에서도 서로 가까이 위치하게 됩니다.\n",
        "\n",
        "임베딩 공간에서 단어들 사이의 거리는 의미적 유사성을 반영합니다. 이 거리를 측정하는 방법은 다음 섹션에서 살펴보겠습니다.\n",
        "\n",
        "## 23-2 단어들 사이의 관계 파악하기\n",
        "\n",
        "### 임베딩 벡터로 단어 간 유사도 계산하기\n",
        "\n",
        "단어를 벡터로 표현했다면, 다음 단계는 이 벡터들 사이의 관계를 수학적으로 계산하는 것입니다. 단어 간 유사도를 계산하는 가장 기본적인 방법은 내적(dot product)을 사용하는 것입니다.\n",
        "\n",
        "### 내적 계산하기\n",
        "\n",
        "내적은 두 벡터의 각 차원별 값을 곱한 후 모두 더하는 연산입니다. 내적 값이 클수록 두 벡터(단어)가 유사하다고 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "귤 • 딸기: 30\n",
            "귤 • 웃다: 0\n"
          ]
        }
      ],
      "source": [
        "def dot_product(vec1, vec2):\n",
        "    return np.dot(vec1, vec2)\n",
        "\n",
        "# 예제 단어들 사이의 내적 계산\n",
        "print(\"귤 • 딸기:\", dot_product(word_embeddings['귤'], word_embeddings['딸기']))\n",
        "print(\"귤 • 웃다:\", dot_product(word_embeddings['귤'], word_embeddings['웃다']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드의 결과를 보면, '귤'과 '딸기'의 내적은 30으로 상당히 높은 값을 가집니다. 이는 두 단어가 의미적으로 유사함을 나타냅니다. 반면, '귤'과 '웃다'의 내적은 0으로, 이 두 단어는 의미적으로 관련이 없음을 보여줍니다.\n",
        "\n",
        "내적은 간단하지만 벡터의 크기에 영향을 받는다는 단점이 있습니다. 이 문제를 해결하기 위해 코사인 유사도를 사용합니다.\n",
        "\n",
        "### 코사인 유사도 계산하기\n",
        "\n",
        "코사인 유사도는 벡터의 크기에 영향을 받지 않고 오직 벡터의 방향만을 고려하는 유사도 측정 방법입니다. 코사인 유사도는 -1(완전히 반대)부터 1(완전히 동일) 사이의 값을 가집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "귤 • 귤 유사성: 1.00\n",
            "귤 • 딸기 유사성: 1.00\n",
            "귤 • 수박 유사성: 0.99\n",
            "귤 • 미소짓다 유사성: 0.16\n",
            "귤 • 화내다 유사성: 0.00\n",
            "귤 • 웃다 유사성: 0.00\n",
            "딸기 • 귤 유사성: 1.00\n",
            "딸기 • 딸기 유사성: 1.00\n",
            "딸기 • 수박 유사성: 0.99\n",
            "딸기 • 미소짓다 유사성: 0.16\n",
            "딸기 • 화내다 유사성: 0.00\n",
            "딸기 • 웃다 유사성: 0.00\n",
            "수박 • 귤 유사성: 0.99\n",
            "수박 • 딸기 유사성: 0.99\n",
            "수박 • 수박 유사성: 1.00\n",
            "수박 • 미소짓다 유사성: 0.32\n",
            "수박 • 화내다 유사성: 0.16\n",
            "수박 • 웃다 유사성: 0.16\n",
            "미소짓다 • 귤 유사성: 0.16\n",
            "미소짓다 • 딸기 유사성: 0.16\n",
            "미소짓다 • 수박 유사성: 0.32\n",
            "미소짓다 • 미소짓다 유사성: 1.00\n",
            "미소짓다 • 화내다 유사성: 0.99\n",
            "미소짓다 • 웃다 유사성: 0.99\n",
            "화내다 • 귤 유사성: 0.00\n",
            "화내다 • 딸기 유사성: 0.00\n",
            "화내다 • 수박 유사성: 0.16\n",
            "화내다 • 미소짓다 유사성: 0.99\n",
            "화내다 • 화내다 유사성: 1.00\n",
            "화내다 • 웃다 유사성: 1.00\n",
            "웃다 • 귤 유사성: 0.00\n",
            "웃다 • 딸기 유사성: 0.00\n",
            "웃다 • 수박 유사성: 0.16\n",
            "웃다 • 미소짓다 유사성: 0.99\n",
            "웃다 • 화내다 유사성: 1.00\n",
            "웃다 • 웃다 유사성: 1.00\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "words = list(word_embeddings.keys())\n",
        "embedding_vectors = np.array(list(word_embeddings.values()))\n",
        "\n",
        "# 코사인 유사성 계산\n",
        "similarities = []\n",
        "for v1 in embedding_vectors:\n",
        "    row = []\n",
        "    for v2 in embedding_vectors:\n",
        "        row.append(cosine_similarity(v1, v2))\n",
        "    similarities.append(row)\n",
        "\n",
        "# 결과 출력\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        print(f\"{words[i]} • {words[j]} 유사성: {similarities[i][j]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "코사인 유사도 계산 결과를 보면, 과일들 사이(귤-딸기, 귤-수박, 딸기-수박)와 감정 표현들 사이(미소짓다-화내다, 미소짓다-웃다, 화내다-웃다)의 유사도가 높은 것을 확인할 수 있습니다. 반면, 과일과 감정 표현 사이의 유사도는 낮습니다.\n",
        "\n",
        "이러한 유사도 계산은 단어 추천, 의미 검색, 단어 간 관계 파악 등 다양한 자연어처리 작업의 기초가 됩니다. 특히 단어 임베딩의 가장 큰 장점은 \"왕 - 남자 + 여자 = 여왕\"과 같은 단어 벡터 연산이 가능하다는 점인데, 이는 다음 섹션에서 살펴보겠습니다.\n",
        "\n",
        "## 23-3 단어 사이의 관계 수정하기\n",
        "\n",
        "### 문맥에 따른 단어 의미 변화 이해하기\n",
        "\n",
        "자연어에서 단어의 의미는 문맥에 따라 달라질 수 있습니다. 예를 들어, '사과'라는 단어는 과일을 의미할 수도 있고, 잘못을 인정하고 용서를 구하는 행위를 의미할 수도 있습니다. 현대 AI 모델은 이러한 문맥 의존적 의미를 파악하기 위해 단어 임베딩을 문맥에 따라 동적으로 조정합니다.\n",
        "\n",
        "### 관계 업데이트\n",
        "\n",
        "아래 코드에서는 '사과'라는 단어의 의미를 과일 쪽으로 또는 행위 쪽으로 조정하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "업데이트 이전의 사과 벡터 (사과_?): [3 3]\n",
            "업데이트된 사과 벡터 (사과_과일): [2.00297944 3.99702056]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/k8/xzy6lbhd1zz_kl7_542fzclm0000gn/T/ipykernel_32628/756846971.py:2: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n"
          ]
        }
      ],
      "source": [
        "def update_vector(vector, target_vector, similarity_value, learning_rate):\n",
        "    new_vector = vector + learning_rate * (target_vector - vector) * similarity_value\n",
        "    return new_vector\n",
        "\n",
        "# 기존 딕셔너리에 추가\n",
        "word_embeddings['사과'] = np.array([3, 3])  # '사과' 초기 값 추가\n",
        "word_embeddings['과'] = np.array([0, 0])    # '과' 벡터 추가\n",
        "\n",
        "# 벡터 값 가져오기\n",
        "귤 = word_embeddings['귤']\n",
        "사과 = word_embeddings['사과']\n",
        "과 = word_embeddings['과']\n",
        "\n",
        "# '귤과 사과' 문장의 각 단어별 코사인 유사도\n",
        "cosine_귤_사과 = cosine_similarity(귤, 사과)\n",
        "cosine_과_사과 = cosine_similarity(과, 사과)\n",
        "\n",
        "# 학습률1의 예\n",
        "learning_rate1 = 0.47\n",
        "\n",
        "# '사과' 벡터를 '귤' 쪽으로 업데이트\n",
        "print(f\"업데이트 이전의 사과 벡터 (사과_?): {사과}\")\n",
        "사과_과일 = update_vector(사과, 귤, cosine_귤_사과, learning_rate1)\n",
        "print(f\"업데이트된 사과 벡터 (사과_과일): {사과_과일}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드에서 `update_vector` 함수는 단어 벡터를 특정 방향으로 조정합니다. 초기에 '사과'는 [3, 3]으로 중립적인 위치에 있지만, '귤' 쪽으로 업데이트하면 과일의 의미가 강해집니다.\n",
        "\n",
        "`learning_rate`는 얼마나 크게 벡터를 업데이트할지 결정하는 파라미터로, 값이 클수록 더 많이 조정됩니다. `similarity_value`는 현재 두 단어 간의 유사도로, 유사할수록 더 많이 업데이트됩니다.\n",
        "\n",
        "### 다양한 문맥에서의 단어 의미 변화\n",
        "\n",
        "다음 코드는 '사과'라는 단어가 문맥에 따라 어떻게 다른 의미로 해석될 수 있는지 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "업데이트 이전의 사과 벡터 (사과_?): [3 3]\n",
            "업데이트된 사과 벡터 (사과_과일): [2.00297944 3.99702056]\n",
            "업데이트된 사과 벡터 (사과_행위): [3.99067604 2.00932396]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/k8/xzy6lbhd1zz_kl7_542fzclm0000gn/T/ipykernel_32628/4197913998.py:15: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return dot_product / (norm_v1 * norm_v2)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50612 (\\N{HANGUL SYLLABLE EO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/Users/string/opt/anaconda3/envs/crawler-arm/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50948 (\\N{HANGUL SYLLABLE WI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 초기 벡터값 설정\n",
        "사과 = np.array([3, 3])\n",
        "귤 = np.array([0, 6])\n",
        "과 = np.array([0, 0])\n",
        "을 = np.array([0, 0])\n",
        "어제일 = np.array([6, 0])\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "    return dot_product / (norm_v1 * norm_v2)\n",
        "\n",
        "def update_vector(vector, target_vector, similarity_value, learning_rate):\n",
        "    new_vector = vector + learning_rate * (target_vector - vector) * similarity_value\n",
        "    return new_vector\n",
        "\n",
        "# '귤과 사과' 문장의 각 단어별 코사인 유사도\n",
        "cosine_귤_사과 = cosine_similarity(귤, 사과)\n",
        "cosine_과_사과 = cosine_similarity(과, 사과)\n",
        "\n",
        "# 학습률1을 설정하겠습니다.\n",
        "learning_rate1 = 0.47\n",
        "\n",
        "# '사과' 벡터를 '귤' 쪽으로 업데이트\n",
        "print(f\"업데이트 이전의 사과 벡터 (사과_?): {사과}\")\n",
        "사과_과일 = update_vector(사과, 귤, cosine_귤_사과, learning_rate1)\n",
        "print(f\"업데이트된 사과 벡터 (사과_과일): {사과_과일}\")\n",
        "\n",
        "# '어제일을 사과' 문장의 각 단어별 코사인 유사도\n",
        "cosine_어제일_사과 = cosine_similarity(어제일, 사과_과일)\n",
        "cosine_을_사과 = cosine_similarity(을, 사과_과일)\n",
        "\n",
        "# 학습률2를 설정하겠습니다.\n",
        "learning_rate2 = 1.11\n",
        "\n",
        "# '사과' 벡터를 '어제일' 쪽으로 업데이트\n",
        "사과_행위 = update_vector(사과_과일, 어제일, cosine_어제일_사과, learning_rate2)\n",
        "print(f\"업데이트된 사과 벡터 (사과_행위): {사과_행위}\")\n",
        "\n",
        "# 단어 임베딩 시각화\n",
        "word_embeddings = {\n",
        "    \"사과_?\": 사과,\n",
        "    \"귤\": 귤,\n",
        "    \"어제일\": 어제일,\n",
        "    \"사과_과일\": 사과_과일,\n",
        "    \"사과_행위\": 사과_행위\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "for word, vec in word_embeddings.items():\n",
        "    plt.scatter(*vec)\n",
        "    plt.text(vec[0] + 0.1, vec[1], word, fontsize=12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드에서는 다음과 같은 두 가지 문맥에서 '사과'의 의미를 조정했습니다:\n",
        "\n",
        "1. \"귤과 사과\" - 여기서 '사과'는 과일 의미로 사용됩니다.\n",
        "2. \"어제일을 사과\" - 여기서 '사과'는 잘못을 인정하고 용서를 구하는 행위로 사용됩니다.\n",
        "\n",
        "시각화 결과를 보면 초기의 중립적인 '사과_?'가 문맥에 따라 '사과_과일'(위쪽, 과일 영역) 또는 '사과_행위'(오른쪽, 행위 영역)로 이동한 것을 확인할 수 있습니다.\n",
        "\n",
        "이렇게 단어의 의미를 문맥에 따라 동적으로 조정하는 능력은 현대 자연어처리 모델의 핵심 기능입니다. 특히 BERT, GPT 같은 트랜스포머 기반 모델들은 이러한 문맥적 의미 파악을 위해 어텐션 메커니즘을 사용하는데, 이는 다음 섹션에서 더 자세히 살펴보겠습니다.\n",
        "\n",
        "## 23-4 AI가 문맥을 파악하는 법\n",
        "\n",
        "### 트랜스포머: 현대 AI의 문맥 파악 기술\n",
        "\n",
        "지금까지 우리는 단어 임베딩과 단어 간 관계를 살펴보았습니다. 이제 현대 AI가 어떻게 문맥을 파악하는지 알아보겠습니다. 현재 자연어처리 분야를 지배하고 있는 아키텍처는 '트랜스포머(Transformer)'입니다. 트랜스포머는 2017년 Google에서 발표한 \"Attention is All You Need\" 논문에서 소개되었으며, GPT, BERT와 같은 대형 언어 모델들의 기반이 되었습니다.\n",
        "\n",
        "트랜스포머의 핵심은 '어텐션(Attention)' 메커니즘입니다. 어텐션은 모델이 문장 내 모든 단어 사이의 관계를 동시에 파악할 수 있게 해주는 기술입니다.\n",
        "\n",
        "### 임베딩 행렬의 형태\n",
        "\n",
        "트랜스포머 모델에서는 문장의 각 단어를 벡터로 변환한 후, 이를 행렬 형태로 모읍니다. 아래 코드에서는 4개 토큰으로 이루어진 문장(\"커피 한잔 어때\")을 512차원 벡터로 임베딩하는 과정을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 형태: (4, 512)\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# 단어와 해당 임베딩 벡터를 딕셔너리로 정의합니다.\n",
        "# 실제로는 사전 훈련된 임베딩 벡터를 사용하는 것이 일반적입니다.\n",
        "embedding_dict = {\n",
        "    '커피': np.random.rand(512),\n",
        "    '한잔': np.random.rand(512),\n",
        "    '어때': np.random.rand(512),\n",
        "    'PAD': np.zeros(512)  # 패딩 벡터는 0으로 채웁니다.\n",
        "}\n",
        "\n",
        "# 입력 문장\n",
        "sentence = ['커피', '한잔', '어때']\n",
        "max_len = 4  # 최대 문장 길이\n",
        "tokens = sentence + ['PAD'] * (max_len - len(sentence))  # 패딩 적용\n",
        "\n",
        "# 토큰을 임베딩 벡터로 변환\n",
        "embeddings = np.array([embedding_dict[token] for token in tokens])\n",
        "print(\"임베딩 행렬의 형태:\", embeddings.shape)  # (4, 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드는 4개의 토큰(3개 단어 + 1개 패딩)을 각각 512차원 벡터로 표현하여 (4, 512) 형태의 행렬을 만듭니다. 패딩(PAD)은 서로 다른 길이의 문장을 동일한 형태로 처리하기 위해 사용됩니다.\n",
        "\n",
        "### 멀티 헤드 어텐션\n",
        "\n",
        "트랜스포머의 핵심 아이디어 중 하나는 '멀티 헤드 어텐션'입니다. 이는 하나의 어텐션 메커니즘을 사용하는 대신, 여러 개의 어텐션 헤드를 사용하여 다양한 관점에서 문맥을 파악하는 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "각 헤드의 형태: (4, 64)\n"
          ]
        }
      ],
      "source": [
        "num_heads = 8\n",
        "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
        "\n",
        "# 임베딩을 8개의 헤드로 분할\n",
        "heads = np.split(embeddings, num_heads, axis=1)\n",
        "print(\"각 헤드의 형태:\", heads[0].shape)  # (4, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "임베딩 벡터를 8개의 헤드로 나누면, 각 헤드는 (4, 64) 형태가 됩니다. 각 헤드는 서로 다른 관점에서 문맥을 파악하는 역할을 합니다.\n",
        "\n",
        "### 어텐션 계산 과정\n",
        "\n",
        "트랜스포머에서 어텐션은 세 가지 복사본을 만들어 계산합니다. 이를 쿼리(Query), 키(Key), 밸류(Value)라고 부릅니다. 이들의 내적을 계산하여 단어 간 관계를 파악합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "내적 결과 행렬의 형태: (4, 4)\n"
          ]
        }
      ],
      "source": [
        "# 첫 번째 헤드 선택\n",
        "head_1 = heads[0]\n",
        "\n",
        "# 복사1과 복사2 생성\n",
        "copy1 = head_1\n",
        "copy2 = head_1.T\n",
        "\n",
        "# 내적 계산\n",
        "attention_scores = np.dot(copy1, copy2)\n",
        "print(\"내적 결과 행렬의 형태:\", attention_scores.shape)  # (4, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "내적 계산 결과는 (4, 4) 형태의 행렬이 됩니다. 이 행렬은 문장 내 모든 단어 쌍 사이의 관계 점수를 나타냅니다. 예를 들어, (0, 1) 위치의 값은 첫 번째 단어('커피')와 두 번째 단어('한잔') 사이의 관계 점수입니다.\n",
        "\n",
        "### 밸류 벡터와의 결합\n",
        "\n",
        "어텐션 점수가 계산되면, 이를 밸류 벡터와 결합하여 문맥이 반영된 새로운 표현을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "복원된 헤드의 형태: (4, 64)\n"
          ]
        }
      ],
      "source": [
        "# 복사3 생성\n",
        "copy3 = embeddings[:, :head_dim]\n",
        "\n",
        "# 다시 4x64 형태로 변환\n",
        "restored_head = np.dot(attention_scores, copy3)\n",
        "print(\"복원된 헤드의 형태:\", restored_head.shape)  # (4, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "어텐션 점수 행렬과 밸류 벡터를 곱하면, 각 단어의 표현이 문맥을 반영하여 업데이트됩니다. 이렇게 생성된 새로운 표현은 원래와 같은 (4, 64) 형태를 갖습니다.\n",
        "\n",
        "### 최종 출력\n",
        "\n",
        "모든 헤드에서 이 과정을 반복한 후, 결과를 결합하여 최종 출력을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최종 출력 행렬의 형태: (4, 512)\n"
          ]
        }
      ],
      "source": [
        "restored_heads = []\n",
        "\n",
        "for i in range(num_heads):\n",
        "    head = heads[i]\n",
        "    copy1 = head\n",
        "    copy2 = head.T\n",
        "    attention_scores = np.dot(copy1, copy2)\n",
        "    copy3 = embeddings[:, i*head_dim:(i+1)*head_dim]\n",
        "    restored_head = np.dot(attention_scores, copy3)\n",
        "    restored_heads.append(restored_head)\n",
        "\n",
        "# 모든 헤드를 결합하여 원래 차원으로 복원\n",
        "final_output = np.concatenate(restored_heads, axis=1)\n",
        "print(\"최종 출력 행렬의 형태:\", final_output.shape)  # (4, 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "각 헤드에서 생성된 결과를 결합하면 원래와 같은 (4, 512) 형태의 행렬이 됩니다. 하지만 이제 각 단어의 표현은 문장 내 다른 단어들과의 관계를 반영하고 있습니다. 예를 들어, '사과'라는 단어가 '먹다'와 함께 등장했다면, '사과'의 임베딩은 과일로서의 의미가 강화됩니다.\n",
        "\n",
        "이러한 방식으로 트랜스포머 모델은 단어들 사이의 관계를 파악하고, 문맥에 따라 단어의 의미를 동적으로 조정할 수 있습니다. 이는 \"나는 사과를 먹었다\"와 \"나는 실수를 사과했다\"에서 '사과'의 다른 의미를 파악하는 데 도움이 됩니다.\n",
        "\n",
        "다음 섹션에서는 트랜스포머의 핵심 구성 요소인 쿼리, 키, 밸류에 대해 더 자세히 알아보겠습니다.\n",
        "\n",
        "## 23-5 질문(쿼리), 단서(키), 답변(밸류)\n",
        "\n",
        "### 어텐션 메커니즘의 핵심 구성 요소\n",
        "\n",
        "앞서 트랜스포머 모델이 어텐션 메커니즘을 통해 문맥을 파악한다고 설명했습니다. 이제 어텐션의 핵심 구성 요소인 쿼리(Query), 키(Key), 밸류(Value)에 대해 더 자세히 알아보겠습니다.\n",
        "\n",
        "쿼리, 키, 밸류는 인간의 정보 검색 과정을 모방한 개념입니다. 간단히 비유하자면:\n",
        "\n",
        "- **쿼리(Query)**: 우리가 찾고자 하는 정보나 질문입니다. 예를 들어 \"오늘 날씨는?\"\n",
        "- **키(Key)**: 찾고자 하는 정보의 위치나 단서입니다. 예를 들어 책의 색인이나 인터넷 검색에서의 키워드\n",
        "- **밸류(Value)**: 실제 정보 내용입니다. 예를 들어 \"오늘은 맑고 화창합니다.\"\n",
        "\n",
        "트랜스포머에서는 쿼리, 키, 밸류를 각각 행렬 연산을 통해 생성합니다. 이들은 모두 동일한 임베딩 벡터에서 시작하지만, 서로 다른 가중치 행렬과의 곱셈을 통해 다른 역할을 수행하게 됩니다.\n",
        "\n",
        "### 쿼리, 키, 밸류 행렬 초기화\n",
        "\n",
        "아래 코드는 쿼리, 키, 밸류 행렬을 초기화하는 과정을 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "쿼리 행렬의 형태: (4, 64)\n",
            "키 행렬의 형태: (64, 4)\n",
            "밸류 행렬의 형태: (4, 64)\n"
          ]
        }
      ],
      "source": [
        "# 쿼리, 키, 밸류 행렬 초기화\n",
        "num_heads = 8\n",
        "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
        "heads = np.split(embeddings, num_heads, axis=1)\n",
        "queries = heads.copy()\n",
        "keys = [head.T for head in heads]\n",
        "values = heads.copy()\n",
        "\n",
        "print(\"쿼리 행렬의 형태:\", queries[0].shape)  # (4, 64)\n",
        "print(\"키 행렬의 형태:\", keys[0].shape)  # (64, 4)\n",
        "print(\"밸류 행렬의 형태:\", values[0].shape)  # (4, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **쿼리(Queries)**: 각 단어가 다른 단어들에 대해 물어보는 질문입니다. 형태는 (문장 길이, 헤드 차원)\n",
        "- **키(Keys)**: 각 단어가 쿼리에 대해 제공하는 답변의 \"관련성\"입니다. 형태는 (헤드 차원, 문장 길이)\n",
        "- **밸류(Values)**: 실제 정보 내용으로, 쿼리와 관련된 키를 통해 가져오는 값입니다. 형태는 (문장 길이, 헤드 차원)\n",
        "\n",
        "### 어텐션 점수 계산 및 스케일링\n",
        "\n",
        "쿼리와 키의 내적을 계산하여 어텐션 점수를 구합니다. 이 점수는 각 단어가 다른 단어에 얼마나 \"주목\"해야 하는지를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "스케일링 전 어텐션 스코어:\n",
            "[[24.15812898 13.4829892  16.65117987  0.        ]\n",
            " [13.4829892  17.05270352 12.38579217  0.        ]\n",
            " [16.65117987 12.38579217 21.32437889  0.        ]\n",
            " [ 0.          0.          0.          0.        ]]\n",
            "스케일링 후 어텐션 스코어:\n",
            "[[3.01976612 1.68537365 2.08139748 0.        ]\n",
            " [1.68537365 2.13158794 1.54822402 0.        ]\n",
            " [2.08139748 1.54822402 2.66554736 0.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# 스케일링 전\n",
        "attention_scores = np.dot(queries[0], keys[0])\n",
        "print(\"스케일링 전 어텐션 스코어:\")\n",
        "print(attention_scores)\n",
        "\n",
        "# 스케일링을 위한 헤드 차원의 제곱근 계산\n",
        "scaling_factor = np.sqrt(head_dim)\n",
        "\n",
        "# 스케일링 후\n",
        "scaled_attention_scores = attention_scores / scaling_factor\n",
        "print(\"스케일링 후 어텐션 스코어:\")\n",
        "print(scaled_attention_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "어텐션 점수는 차원이 커질수록 값이 커지는 경향이 있어, 소프트맥스 함수가 극단적인 값을 갖게 될 수 있습니다. 이를 방지하기 위해 헤드 차원의 제곱근으로 나누는 스케일링 작업을 수행합니다.\n",
        "\n",
        "### 소프트맥스 적용 및 마스킹\n",
        "\n",
        "스케일링된 어텐션 점수에 소프트맥스 함수를 적용하여 확률 분포로 변환합니다. 이 확률 분포는 각 단어가 다른 단어에 얼마나 주목해야 하는지의 가중치가 됩니다.\n",
        "\n",
        "또한, 패딩 토큰에는 주목하지 않도록 마스킹 작업을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "소프트맥스 적용 후 어텐션 스코어:\n",
            "[[0.60438163 0.15914462 0.23647375 0.        ]\n",
            " [0.29118643 0.45494567 0.25386791 0.        ]\n",
            " [0.29583999 0.17358116 0.53057886 0.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# 패딩 부분을 -∞로 채운 마스크 행렬 준비\n",
        "mask = np.zeros_like(scaled_attention_scores)\n",
        "mask[:, -1] = -np.inf  # 마지막 열을 패딩 처리\n",
        "mask[-1, :] = -np.inf  # 마지막 행을 패딩 처리\n",
        "\n",
        "# 소프트맥스 적용 함수\n",
        "def masked_softmax(x, mask):\n",
        "    x_exp = np.exp(x - np.max(x, axis=-1, keepdims=True))  # 오버플로 방지\n",
        "    x_exp = x_exp * (mask != -np.inf)  # 마스크된 부분은 0으로 처리\n",
        "    x_sum = np.sum(x_exp, axis=-1, keepdims=True) # 지수 값의 합 계산\n",
        "    x_sum = np.where(x_sum == 0, 1, x_sum)  # 0으로 나누는 것을 방지하기 위해 합이 0인 경우 1로 설정\n",
        "    return x_exp / x_sum # 소프트맥스 계산\n",
        "\n",
        "# 소프트맥스 적용\n",
        "attention_probs = masked_softmax(scaled_attention_scores, mask)\n",
        "print(\"소프트맥스 적용 후 어텐션 스코어:\")\n",
        "print(attention_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "마스킹은 패딩 토큰과 같이 실제 의미가 없는 토큰에 주목하지 않도록 하는 기법입니다. 마스킹된 위치의 값을 -무한대로 설정하면 소프트맥스 적용 후 해당 위치의 확률은 0이 됩니다.\n",
        "\n",
        "### 최종 어텐션 출력 계산\n",
        "\n",
        "소프트맥스로 변환된 어텐션 확률과 밸류 행렬을 곱하여 최종 어텐션 출력을 계산합니다. 이 출력은 각 단어가 문맥 내 다른 단어들의 정보를 얼마나 반영해야 하는지를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "어텐션 출력의 형태: (4, 64)\n"
          ]
        }
      ],
      "source": [
        "# 최종 어텐션 출력 계산 (소프트맥스 확률 * 밸류)\n",
        "attention_output = np.matmul(attention_probs, values[0])\n",
        "print(\"어텐션 출력의 형태:\", attention_output.shape)  # (4, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 과정을 통해 각 단어의 표현은 문맥 내 다른 단어들의 정보를 반영하여 업데이트됩니다. 예를 들어, \"은행에 갔다\"라는 문장에서 '은행'이라는 단어는 '갔다'라는 단어와의 관계를 통해 금융 기관으로서의 의미가 강화될 수 있습니다.\n",
        "\n",
        "### 트랜스포머의 자기 주의 메커니즘\n",
        "\n",
        "트랜스포머의 어텐션은 \"자기 주의(Self-Attention)\" 메커니즘이라고도 불립니다. 이는 같은 문장 내에서 단어들이 서로를 참조하기 때문입니다. 이 메커니즘을 통해 모델은 문장 내의 장거리 의존성을 효과적으로 처리할 수 있습니다.\n",
        "\n",
        "자기 주의 메커니즘은 인간이 문장을 이해하는 방식과 유사합니다. 우리도 문장을 읽을 때 현재 단어의 의미를 파악하기 위해 문장 내 다른 단어들을 참조합니다. 트랜스포머는 이러한 인간의 인지 과정을 수학적으로 모델링한 것입니다.\n",
        "\n",
        "다음 섹션에서는 여러 문장에 대한 트랜스포머 어텐션을 적용하는 방법을 살펴보겠습니다.\n",
        "\n",
        "## 23-6 트랜스포머를 위한 어텐션 만들기\n",
        "\n",
        "### 실제 문장들에 트랜스포머 적용하기\n",
        "\n",
        "지금까지 우리는 트랜스포머의 기본 원리와 어텐션 메커니즘의 작동 방식을 살펴보았습니다. 이제 실제 여러 문장에 트랜스포머를 적용하는 방법을 알아보겠습니다.\n",
        "\n",
        "실제 자연어처리 모델에서는 한 번에의 여러 문장(배치)을 처리합니다. 이는 계산 효율성을 높이고 모델의 학습 속도를 향상시킵니다. 따라서 어텐션 메커니즘도 여러 문장을 동시에 처리할 수 있어야 합니다.\n",
        "\n",
        "### 여러 문장의 임베딩\n",
        "\n",
        "여러 문장을 임베딩하면 3차원 텐서가 됩니다: (배치 크기, 문장 길이, 임베딩 차원)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 형태: (3, 5, 512)\n"
          ]
        }
      ],
      "source": [
        "# 입력 문장\n",
        "sentences = [\n",
        "    ['<sos>', '커피', '한잔', '어때', '<eos>'],\n",
        "    ['<sos>', '오늘', '날씨', '좋네', '<eos>'],\n",
        "    ['<sos>', '옷이', '어울려요', '<eos>', 'PAD']\n",
        "]\n",
        "\n",
        "# 단어와 해당 임베딩 벡터를 딕셔너리로 정의합니다.\n",
        "embedding_dict = {\n",
        "    '<sos>': np.random.rand(512),\n",
        "    '<eos>': np.random.rand(512),\n",
        "    '커피': np.random.rand(512),\n",
        "    '한잔': np.random.rand(512),\n",
        "    '어때': np.random.rand(512),\n",
        "    '오늘': np.random.rand(512),\n",
        "    '날씨': np.random.rand(512),\n",
        "    '좋네': np.random.rand(512),\n",
        "    '옷이': np.random.rand(512),\n",
        "    '어울려요': np.random.rand(512),\n",
        "    'PAD': np.zeros(512)  # 패딩 벡터는 0으로 채웁니다.\n",
        "}\n",
        "\n",
        "max_len = 5  # 최대 문장 길이\n",
        "\n",
        "# 토큰을 임베딩 벡터로 변환\n",
        "embeddings = np.array([[embedding_dict[token] for token in sentence] for sentence in sentences])\n",
        "print(\"임베딩 행렬의 형태:\", embeddings.shape)  # (3, 5, 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "위 코드에서는 3개의 문장을 각각 5개의 토큰으로 표현하고, 각 토큰을 512차원 벡터로 임베딩합니다. 결과는 (3, 5, 512) 형태의 3차원 텐서입니다.\n",
        "\n",
        "* 첫 번째 차원(3): 배치 크기, 즉 처리하는 문장의 수\n",
        "* 두 번째 차원(5): 각 문장의 최대 길이\n",
        "* 세 번째 차원(512): 임베딩 벡터의 차원\n",
        "\n",
        "실제 모델에서는 문장의 시작(`<sos>`)과 끝(`<eos>`)을 나타내는 특수 토큰을 추가하고, 짧은 문장은 패딩 토큰(`PAD`)으로 채웁니다.\n",
        "\n",
        "### 여러 문장에서의 쿼리, 키, 밸류 계산\n",
        "\n",
        "배치 처리를 위해 쿼리, 키, 밸류도 3차원 텐서로 확장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "쿼리 행렬의 형태: (3, 5, 64)\n",
            "키 행렬의 형태: (3, 64, 5)\n",
            "밸류 행렬의 형태: (3, 5, 64)\n"
          ]
        }
      ],
      "source": [
        "# 쿼리, 키, 밸류 행렬 초기화\n",
        "num_heads = 8\n",
        "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
        "heads = np.split(embeddings, num_heads, axis=2) # 512차원 임베딩 벡터를 8개의 헤드로 분할하여 heads에 저장\n",
        "queries = heads.copy()\n",
        "keys = [head.transpose(0, 2, 1) for head in heads] # 키 행렬을 각 헤드의 전치를 통해 초기화 (첫 번째 축: 배치 크기, 두 번째 축: 문장 길이, 세 번째 축: 헤드 차원)\n",
        "values = heads.copy()\n",
        "\n",
        "print(\"쿼리 행렬의 형태:\", queries[0].shape)  # (3, 5, 64)\n",
        "print(\"키 행렬의 형태:\", keys[0].shape)  # (3, 64, 5)\n",
        "print(\"밸류 행렬의 형태:\", values[0].shape)  # (3, 5, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "여기서 주목할 점은 키 행렬의 형태가 (3, 64, 5)인데, 이는 전치 연산을 통해 두 번째와 세 번째 차원이 바뀌었기 때문입니다. 이렇게 하면 쿼리와 키의 내적이 (3, 5, 5) 형태의 어텐션 점수 행렬이 됩니다.\n",
        "\n",
        "### 배치 처리를 위한 어텐션 계산\n",
        "\n",
        "이제 배치 내 모든 문장에 대해 어텐션을 동시에 계산합니다. 이 과정은 앞서 설명한 단일 문장에 대한 어텐션 계산과 유사하지만, 배치 차원을 추가로 고려해야 합니다.\n",
        "\n",
        "1. 쿼리와 키의 내적 계산\n",
        "2. 스케일링 적용\n",
        "3. 패딩 마스킹\n",
        "4. 소프트맥스 적용\n",
        "5. 밸류와의 곱셈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'softmax' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m attention_scores = np.where(padding_mask, -np.inf, attention_scores)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 소프트맥스 적용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m attention_weights = \u001b[43msoftmax\u001b[49m(attention_scores)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 밸류와의 곱셈\u001b[39;00m\n\u001b[32m     25\u001b[39m attention_output = np.matmul(attention_weights, value)\n",
            "\u001b[31mNameError\u001b[39m: name 'softmax' is not defined"
          ]
        }
      ],
      "source": [
        "# 전체 코드 실행 예시\n",
        "import numpy as np\n",
        "\n",
        "# 전체 출력 형식을 소수점 이하 네 자리로 설정\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "\n",
        "# 각 헤드별 어텐션 계산\n",
        "for i in range(num_heads):\n",
        "    query = queries[i]\n",
        "    key = keys[i]\n",
        "    value = values[i]\n",
        "\n",
        "    # 내적 계산 후 스케일링\n",
        "    attention_scores = np.matmul(query, key) / scaling_factor\n",
        "\n",
        "    # 패딩 처리\n",
        "    padding_mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
        "    padding_mask = padding_mask[:, np.newaxis, :]  # 차원 확장\n",
        "    attention_scores = np.where(padding_mask, -np.inf, attention_scores)\n",
        "\n",
        "    # 소프트맥스 적용\n",
        "    attention_weights = softmax(attention_scores)\n",
        "\n",
        "    # 밸류와의 곱셈\n",
        "    attention_output = np.matmul(attention_weights, value)\n",
        "    \n",
        "    # 이 헤드의 출력 저장\n",
        "    # ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "실제 구현에서는 위 과정이 각 헤드마다 독립적으로 수행되고, 모든 헤드의 출력이 결합되어 최종 출력이 됩니다.\n",
        "\n",
        "### 트랜스포머 모델의 완전한 구조\n",
        "\n",
        "실제 트랜스포머 모델은 위에서 설명한 멀티헤드 어텐션 외에도 여러 구성 요소를 포함합니다:\n",
        "\n",
        "1. **인코더-디코더 구조**: 원본 트랜스포머는 인코더와 디코더로 구성되며, 기계 번역과 같은 시퀀스-투-시퀀스 작업에 사용됩니다.\n",
        "\n",
        "2. **위치 인코딩**: 트랜스포머는 순차적인 정보를 직접 처리하지 않기 때문에, 위치 정보를 별도로 제공해야 합니다. 위치 인코딩을 통해 단어의 순서 정보를 모델에 전달합니다.\n",
        "\n",
        "3. **피드포워드 네트워크**: 각 어텐션 계층 후에는 일반적인 완전 연결 신경망이 있어 모델의 표현력을 높입니다.\n",
        "\n",
        "4. **스킵 연결과 층 정규화**: 깊은 신경망의 학습을 안정화하기 위한 기법들이 적용됩니다.\n",
        "\n",
        "### 트랜스포머의 발전과 응용\n",
        "\n",
        "트랜스포머의 등장 이후 자연어처리 분야는 크게 발전했습니다. 특히 BERT, GPT와 같은 사전 훈련된 대형 언어 모델이 등장하면서 다양한 자연어처리 작업에서 놀라운 성능을 보여주고 있습니다.\n",
        "\n",
        "- **BERT(Bidirectional Encoder Representations from Transformers)**: 트랜스포머의 인코더 부분만을 사용하여 양방향 문맥을 학습합니다. 문장 분류, 개체명 인식 등의 다양한 작업에 활용됩니다.\n",
        "\n",
        "- **GPT(Generative Pre-trained Transformer)**: 트랜스포머의 디코더 부분을 기반으로 하며, 이전 토큰들을 바탕으로 다음 토큰을 예측하는 방식으로 학습합니다. 텍스트 생성, 대화 시스템 등에 활용됩니다.\n",
        "\n",
        "- **T5(Text-to-Text Transfer Transformer)**: 모든 자연어처리 작업을 텍스트-투-텍스트 형식으로 통합하는 접근법을 제시합니다.\n",
        "\n",
        "### 트랜스포머의 한계와 과제\n",
        "\n",
        "트랜스포머의 뛰어난 성능에도 불구하고, 여전히 몇 가지 한계와 과제가 있습니다:\n",
        "\n",
        "1. **계산 복잡도**: 자기 주의 메커니즘의 시간 및 공간 복잡도는 시퀀스 길이의 제곱에 비례합니다. 이는 긴 문서를 처리할 때 메모리 효율성 문제를 야기합니다.\n",
        "\n",
        "2. **표면적 패턴 학습**: 트랜스포머 모델은 종종 텍스트의 표면적 패턴을 학습하지만, 깊은 의미 이해나 추론 능력은 제한적일 수 있습니다.\n",
        "\n",
        "3. **학습 데이터 편향**: 대형 언어 모델은 학습 데이터의 편향을 그대로 반영할 수 있어, 윤리적 문제를 야기할 수 있습니다.\n",
        "\n",
        "이러한 한계를 극복하기 위해 Longformer, Reformer 등의 효율적인 트랜스포머 변형이 연구되고 있으며, 추론 능력을 향상시키기 위한 다양한 접근법이 시도되고 있습니다.\n",
        "\n",
        "### 결론\n",
        "\n",
        "트랜스포머 모델은 어텐션 메커니즘을 통해 문맥을 효과적으로 파악할 수 있으며, 이는 현대 자연어처리의 핵심 기술이 되었습니다. 단어 임베딩부터 어텐션 메커니즘, 그리고 트랜스포머 아키텍처까지 이어지는 발전은 컴퓨터가 인간의 언어를 이해하고 생성하는 능력을 크게 향상시켰습니다.\n",
        "\n",
        "앞으로 자연어처리 기술은 더욱 발전하여, 인간과 기계 사이의 언어 장벽을 허물고 더 자연스러운 상호작용을 가능하게 할 것입니다. 이 과정에서 트랜스포머와 어텐션 메커니즘은 계속해서 중요한 역할을 할 것입니다.\n",
        "\n",
        "## [참고] 그림 속 폰트가 깨지면 실행하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Matplotlib에서 시스템 기본 폰트인 '맑은 고딕' 사용\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 음수 기호 깨짐 방지\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.plot([1, 2, 3, 4])\n",
        "plt.title('한글 폰트 테스트')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "crawler-arm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
